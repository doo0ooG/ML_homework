{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "2cf39e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_exp_name = 'sample'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "30728966",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "from torch.utils.data import ConcatDataset, DataLoader, Subset, Dataset\n",
    "from torchvision.datasets import DatasetFolder, VisionDataset\n",
    "\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "d129d78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def same_seed(myseed):\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(myseed)  \n",
    "    torch.manual_seed(myseed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(myseed)\n",
    "\n",
    "myseed = 6666\n",
    "same_seed(myseed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "6dece7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tfm = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "train_tfm = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "4d4fd0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FoodDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, path, tfm = test_tfm, files = None):\n",
    "        super(FoodDataset).__init__()\n",
    "        self.path = path\n",
    "        self.files = [os.path.join(self.path, x) for x in os.listdir(self.path) if x.endswith('.jpg')]\n",
    "        if files != None:\n",
    "            self.files = files\n",
    "        self.transform = tfm\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        fname = self.files[idx]\n",
    "        im = Image.open(fname)\n",
    "        im = self.transform(im)\n",
    "\n",
    "        try:\n",
    "            label = int(fname.split('\\\\')[-1].split('_')[0])\n",
    "        except:\n",
    "            label = -1\n",
    "        return im, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac4bef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Classifier(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(Classifier, self).__init__()\n",
    "#         # input_dim: (3, 128, 128)\n",
    "        \n",
    "#         self.cnn = nn.Sequential(\n",
    "#             nn.Conv2d(3, 64, 3, 1, 1), # output_dim: (64, 128, 128)\n",
    "#             nn.BatchNorm2d(64),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(2, 2, 0), # output_dim: (64, 64, 64)\n",
    "\n",
    "#             nn.Conv2d(64, 128, 3, 1, 1), # output_dim: (128, 64, 64)\n",
    "#             nn.BatchNorm2d(128),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(2, 2, 1), #output_dim: (128, 32, 32)\n",
    "\n",
    "#             nn.Conv2d(128, 256, 3, 1, 1), # output_dim: (256, 64, 64)\n",
    "#             nn.BatchNorm2d(256),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(2, 2, 1), #output_dim: (256, 16, 16)\n",
    "\n",
    "#             nn.Conv2d(256, 512, 3, 1, 1), # output_dim: (512, 16, 16)\n",
    "#             nn.BatchNorm2d(512),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(2, 2, 0), # output_dim: (512, 8, 8)\n",
    "\n",
    "#             nn.Conv2d(512, 512, 3, 1, 1), # output_dim: (512, 8, 8)\n",
    "#             nn.BatchNorm2d(512),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(2, 2, 0) #output_dim: (512, 4, 4)\n",
    "#         )\n",
    "        \n",
    "#         self.fc = nn.Sequential(\n",
    "#             nn.Linear(512 * 4 * 4, 1024),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(1024, 512),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(512, 11)\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         out = self.cnn(x)\n",
    "#         out = out.view(out.size()[0], -1)\n",
    "#         out = self.fc(out)\n",
    "#         return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "cb06318a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Doog\\AppData\\Roaming\\Python\\Python39\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Doog\\AppData\\Roaming\\Python\\Python39\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "model = models.resnet50(pretrained = True)\n",
    "in_features = model.fc.in_features\n",
    "model.fc = nn.Linear(in_features, 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af89321",
   "metadata": {},
   "source": [
    "Input shape: torch.Size([233, 3, 128, 128])\n",
    "\n",
    "### 逐层输出 shape:\n",
    "- After layer 1 (Conv2d): torch.Size([233, 64, 128, 128])\n",
    "- After layer 2 (BatchNorm2d): torch.Size([233, 64, 128, 128])\n",
    "- After layer 3 (ReLU): torch.Size([233, 64, 128, 128])\n",
    "- After layer 4 (MaxPool2d): torch.Size([233, 64, 64, 64])\n",
    "- After layer 5 (Conv2d): torch.Size([233, 128, 64, 64])\n",
    "- After layer 6 (BatchNorm2d): torch.Size([233, 128, 64, 64])\n",
    "- After layer 7 (ReLU): torch.Size([233, 128, 64, 64])\n",
    "- After layer 8 (MaxPool2d): torch.Size([233, 128, 33, 33])\n",
    "- After layer 9 (Conv2d): torch.Size([233, 256, 33, 33])\n",
    "- After layer 10 (BatchNorm2d): torch.Size([233, 256, 33, 33])\n",
    "- After layer 11 (ReLU): torch.Size([233, 256, 33, 33])\n",
    "- After layer 12 (MaxPool2d): torch.Size([233, 256, 17, 17])\n",
    "- After layer 13 (Conv2d): torch.Size([233, 512, 17, 17])\n",
    "- After layer 14 (BatchNorm2d): torch.Size([233, 512, 17, 17])\n",
    "- After layer 15 (ReLU): torch.Size([233, 512, 17, 17])\n",
    "- After layer 16 (MaxPool2d): torch.Size([233, 512, 8, 8])\n",
    "- After layer 17 (Conv2d): torch.Size([233, 512, 8, 8])\n",
    "- After layer 18 (BatchNorm2d): torch.Size([233, 512, 8, 8])\n",
    "- After layer 19 (ReLU): torch.Size([233, 512, 8, 8])\n",
    "- After layer 20 (MaxPool2d): torch.Size([233, 512, 4, 4])\n",
    "- Before fc (after flattening): torch.Size([233, 512, 4, 4])\n",
    "- After flattening: torch.Size([233, 8192])\n",
    "- After layer 21 (Linear): torch.Size([233, 1024])\n",
    "- After layer 22 (ReLU): torch.Size([233, 1024])\n",
    "- After layer 23 (Linear): torch.Size([233, 512])\n",
    "- After layer 24 (ReLU): torch.Size([233, 512])\n",
    "- After layer 25 (Linear): torch.Size([233, 11])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "b762eac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchviz import make_dot \n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     # 构造一个 shape 为 [233, 3, 128, 128] 的输入 tensor\n",
    "#     x = torch.randn(233, 3, 128, 128)\n",
    "#     print(\"Input shape:\", x.shape)  # 打印输入 shape\n",
    "\n",
    "#     # 创建模型实例\n",
    "#     model = Classifier()\n",
    "\n",
    "#     # 逐层打印模型输出的 shape\n",
    "#     print(\"\\n逐层输出 shape:\")\n",
    "#     out = x\n",
    "#     # 对于 self.cnn 中的每个层依次处理并打印输出 shape\n",
    "#     layer_num = 1\n",
    "#     for layer in model.cnn:\n",
    "#         out = layer(out)\n",
    "#         print(f\"After layer {layer_num} ({layer.__class__.__name__}): {out.shape}\")\n",
    "#         layer_num += 1\n",
    "\n",
    "#     # 展平前的输出 shape\n",
    "#     print(f\"Before fc (after flattening): {out.shape}\")\n",
    "#     out = out.view(out.size()[0], -1)\n",
    "#     print(f\"After flattening: {out.shape}\")\n",
    "\n",
    "#     # 逐层通过全连接层\n",
    "#     for layer in model.fc:\n",
    "#         out = layer(out)\n",
    "#         print(f\"After layer {layer_num} ({layer.__class__.__name__}): {out.shape}\")\n",
    "#         layer_num += 1\n",
    "\n",
    "#     # 使用 torchviz 可视化整个模型的计算图\n",
    "#     # 注意：可视化时需要传入模型的输出及模型参数\n",
    "#     out_graph = model(x)\n",
    "#     dot = make_dot(out_graph, params=dict(model.named_parameters()))\n",
    "#     # 生成 PNG 文件并自动打开（若系统配置支持）\n",
    "#     dot.format = 'png'\n",
    "#     dot.render(\"model_visualization\", view=True)\n",
    "\n",
    "#     print(\"\\n模型计算图已保存为 'model_visualization.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "8d673453",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# model = Classifier().to(device)\n",
    "model = model.to(device)\n",
    "batch_size = 64\n",
    "n_epochs = 20\n",
    "patience = 5\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.0003, weight_decay = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a60903",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "919c3538",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = FoodDataset('./train', tfm = train_tfm)\n",
    "valid_set = FoodDataset('./valid', tfm = test_tfm)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size = batch_size, shuffle = True, num_workers = 0, pin_memory = True)\n",
    "valid_loader = DataLoader(valid_set, batch_size = batch_size, shuffle = True, num_workers = 0, pin_memory = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "48ffc880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b3114341a6c4ea2912d203a951b31cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train | 1 / 20] loss = 0.66632, acc = 0.78384\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f5d14023dbe4b9b80f34c8655fee235",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Valid | 1 / 20] loss = 0.52518, acc = 0.83392\n",
      "[ Valid | 001/020 ] loss = 0.52518, acc = 0.83392 -> best\n",
      "Best model found at epoch 0, saving model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3248ff43bc894d3ab2796f232b22c267",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train | 2 / 20] loss = 0.32465, acc = 0.89510\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3edca5b6284c47c6ba741ca3d4c9bd99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Valid | 2 / 20] loss = 0.55086, acc = 0.83836\n",
      "[ Valid | 002/020 ] loss = 0.55086, acc = 0.83836 -> best\n",
      "Best model found at epoch 1, saving model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4001c7a4a54c43ffba99c23d60dc34a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train | 3 / 20] loss = 0.23646, acc = 0.92436\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c406722427f2439fa00dcbf3fab525d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Valid | 3 / 20] loss = 0.54437, acc = 0.83392\n",
      "[ Valid | 003/020 ] loss = 0.54437, acc = 0.83392\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aa8aba71da04919b95ea7d9bc70c9f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train | 4 / 20] loss = 0.15227, acc = 0.95004\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "350a30b105b54ff18310bf921f1f2a41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Valid | 4 / 20] loss = 0.51084, acc = 0.85834\n",
      "[ Valid | 004/020 ] loss = 0.51084, acc = 0.85834 -> best\n",
      "Best model found at epoch 3, saving model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf0a4bd08b474e8c9d3517f0d27e8d9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train | 5 / 20] loss = 0.09631, acc = 0.96845\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2648c983ec5b47a38f76bf7669217748",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Valid | 5 / 20] loss = 0.52940, acc = 0.84859\n",
      "[ Valid | 005/020 ] loss = 0.52940, acc = 0.84859\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e18da426dc64f548ed9122a85d4490c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train | 6 / 20] loss = 0.12655, acc = 0.95880\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb88fd4fe8da43be8b8304296df68602",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Valid | 6 / 20] loss = 0.62499, acc = 0.83253\n",
      "[ Valid | 006/020 ] loss = 0.62499, acc = 0.83253\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4b10ca6c85f43468190b3dd1d7be127",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train | 7 / 20] loss = 0.09558, acc = 0.96795\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dc81a717f974723b6535bf3ec253db2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Valid | 7 / 20] loss = 0.57696, acc = 0.85218\n",
      "[ Valid | 007/020 ] loss = 0.57696, acc = 0.85218\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a08b5458d4b24a478f2b108251ae7ff5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train | 8 / 20] loss = 0.07224, acc = 0.97582\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3398107e25c41739c41bc91087cb2a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Valid | 8 / 20] loss = 0.70329, acc = 0.82079\n",
      "[ Valid | 008/020 ] loss = 0.70329, acc = 0.82079\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "791741b195ad4e2dbf2b99970c546f95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train | 9 / 20] loss = 0.09663, acc = 0.96935\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9fb0100cd7541138df93ebf4e4a824f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Valid | 9 / 20] loss = 0.84865, acc = 0.79500\n",
      "[ Valid | 009/020 ] loss = 0.84865, acc = 0.79500\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16bc9f5d6e89497c935d53c4cb5fa5c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train | 10 / 20] loss = 0.10359, acc = 0.96676\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "433e16093b6b4c44b9ad927d671568d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Valid | 10 / 20] loss = 0.62979, acc = 0.84414\n",
      "[ Valid | 010/020 ] loss = 0.62979, acc = 0.84414\n",
      "No improvment 5 consecutive epochs, early stopping\n"
     ]
    }
   ],
   "source": [
    "stale = 0\n",
    "best_acc = 0\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "\n",
    "    train_loss = []\n",
    "    train_accs = []\n",
    "\n",
    "    for batch in tqdm(train_loader):\n",
    "        imgs, labels = batch\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        preds = model(imgs)\n",
    "        loss = criterion(preds, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        acc = (preds.argmax(dim = -1) == labels).float().mean()\n",
    "\n",
    "        train_loss.append(loss.item())\n",
    "        train_accs.append(acc.item())\n",
    "        # train_loss.append()\n",
    "    train_loss = sum(train_loss) / len(train_loss)\n",
    "    train_acc = sum(train_accs) / len(train_accs)\n",
    "    print(f'[Train | {epoch + 1} / {n_epochs}] loss = {train_loss:.5f}, acc = {train_acc:.5f}') \n",
    "\n",
    "    model.eval()\n",
    "    valid_loss = []\n",
    "    valid_accs = []\n",
    "\n",
    "    for batch in tqdm(valid_loader):\n",
    "        with torch.no_grad():\n",
    "            imgs, labels = batch\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            preds = model(imgs)\n",
    "            loss = criterion(preds, labels)\n",
    "            acc = (preds.argmax(dim = -1) == labels).float().mean()\n",
    "\n",
    "            valid_loss.append(loss.item())\n",
    "            valid_accs.append(acc.item())\n",
    "\n",
    "    valid_loss = sum(valid_loss) / len(valid_loss)\n",
    "    valid_acc = sum(valid_accs) / len(valid_accs)\n",
    "\n",
    "    print(f'[Valid | {epoch + 1} / {n_epochs}] loss = {valid_loss:.5f}, acc = {valid_acc:.5f}') \n",
    "\n",
    "    # update logs\n",
    "    if valid_acc > best_acc:\n",
    "        with open(f\"./{_exp_name}_log.txt\",\"a\"):\n",
    "            print(f\"[ Valid | {epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f} -> best\")\n",
    "    else:\n",
    "        with open(f\"./{_exp_name}_log.txt\",\"a\"):\n",
    "            print(f\"[ Valid | {epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f}\")\n",
    "\n",
    "\n",
    "    # save models\n",
    "    if valid_acc > best_acc:\n",
    "        print(f\"Best model found at epoch {epoch}, saving model\")\n",
    "        torch.save(model.state_dict(), f\"{_exp_name}_best.ckpt\") # only save best to prevent output memory exceed error\n",
    "        best_acc = valid_acc\n",
    "        stale = 0\n",
    "    else:\n",
    "        stale += 1\n",
    "        if stale > patience:\n",
    "            print(f\"No improvment {patience} consecutive epochs, early stopping\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "88006bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = FoodDataset('./test', test_tfm)\n",
    "test_loader = DataLoader(test_set, batch_size = batch_size, shuffle = False, num_workers = 0, pin_memory = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "c3bcb6f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Doog\\AppData\\Roaming\\Python\\Python39\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Doog\\AppData\\Roaming\\Python\\Python39\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\Doog\\AppData\\Local\\Temp\\ipykernel_28468\\679697845.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_best.load_state_dict(torch.load(f'{_exp_name}_best.ckpt'))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f57955fec434615aa9b88380f69c973",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_best = models.resnet50(pretrained = False)\n",
    "in_features = model_best.fc.in_features\n",
    "model_best.fc = nn.Linear(in_features, 11)\n",
    "model_best = model_best.to(device)\n",
    "model_best.load_state_dict(torch.load(f'{_exp_name}_best.ckpt'))\n",
    "# model_best.load_state_dict(torch.load(f'{_exp_name}_best.ckpt'))\n",
    "model_best.eval()\n",
    "prediction = []\n",
    "with torch.no_grad():\n",
    "    for data, _ in tqdm(test_loader):\n",
    "        data = data.to(device)\n",
    "        preds = model_best(data)\n",
    "        test_label = np.argmax(preds.cpu().data.numpy(), axis = 1)\n",
    "        prediction += test_label.squeeze().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "64c6614d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create test csv\n",
    "def pad4(i):\n",
    "    return \"0\"*(4-len(str(i)))+str(i)\n",
    "df = pd.DataFrame()\n",
    "df[\"Id\"] = [pad4(i) for i in range(len(test_set))]\n",
    "df[\"Category\"] = prediction\n",
    "df.to_csv(\"submission.csv\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98953515",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
